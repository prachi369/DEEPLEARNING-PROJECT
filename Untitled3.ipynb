{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4V41Rm64tivme1o+y5dmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachi369/DEEPLEARNING-PROJECT/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "PQPL8nEWREri",
        "outputId": "be6051fc-f1f0-4d63-ba96-b7b4fe836d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 6 classes.\n",
            "Found 0 images belonging to 6 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The PyDataset has length 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-da50655815a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     ModelCheckpoint(filepath=\"model.h5\",monitor='val_loss',save_best_only=True,verbose=1)]\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m model.fit(training_set,\n\u001b[0m\u001b[1;32m     58\u001b[0m                          \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m             ]\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape = (256, 256, 1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 150, activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 6, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range = 12.,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   zoom_range=0.15,\n",
        "                                   horizontal_flip = True)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('Internship on AI\\\\Day 13 - Hand Gesture Recognition using DL\\\\HandGestureDataset\\\\train',\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 batch_size = 8,\n",
        "                                                 classes = ['NONE','ONE','TWO','THREE','FOUR','FIVE'],\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "val_set = val_datagen.flow_from_directory('Internship on AI\\\\Day 13 - Hand Gesture Recognition using DL\\\\HandGestureDataset\\\\test',\n",
        "                                            target_size = (256, 256),\n",
        "                                            color_mode='grayscale',\n",
        "                                            batch_size = 8,\n",
        "                                            classes=['NONE', 'ONE', 'TWO', 'THREE', 'FOUR', 'FIVE'],\n",
        "                                            class_mode='categorical')\n",
        "\n",
        "\n",
        "callback_list = [\n",
        "    EarlyStopping(monitor='val_loss',patience=10),\n",
        "    ModelCheckpoint(filepath=\"model.h5\",monitor='val_loss',save_best_only=True,verbose=1)]\n",
        "\n",
        "model.fit(training_set,\n",
        "                         steps_per_epoch = 37,\n",
        "                         epochs = 25,\n",
        "                         validation_data = val_set,\n",
        "                         validation_steps = 7,\n",
        "                         callbacks=callback_list\n",
        "                    )"
      ]
    }
  ]
}